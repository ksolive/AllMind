{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e777581",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47e774af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello allmind\n"
     ]
    }
   ],
   "source": [
    "print(\"hello allmind\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c80bb80a",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48ed3c4f",
   "metadata": {},
   "source": [
    "模块类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ffabdc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Plugin:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "\n",
    "    def run(self):\n",
    "        print(f\"Plugin {self.name} is running.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba82726",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Message:\n",
    "    def __init__(self, content):\n",
    "        self.timestamp = datetime.datetime.now()\n",
    "        self.content = content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c9aa44",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TerminalIO:\n",
    "    def __init__(self, prompt=\"> \"):\n",
    "        self.prompt =  prompt\n",
    "\n",
    "    def input(self, prompt):\n",
    "        user_input = input(prompt)\n",
    "        return user_input\n",
    "\n",
    "    def output(self, message):\n",
    "        print(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30681774",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LLM:\n",
    "    def __init__(self, api_key, model, system_prompt):\n",
    "        self.api_key = api_key\n",
    "        self.model = model\n",
    "        self.system_prompt = system_prompt\n",
    "\n",
    "    def plain_chat(message_json):\n",
    "        messages = LLMMessage(content)\n",
    "        return message.content\n",
    "    \n",
    "class LLMMessage:\n",
    "    def __init__(self, role, content):\n",
    "        self.role = role\n",
    "        self.content = content\n",
    "\n",
    "    def to_dict(self):\n",
    "        return {\n",
    "            \"role\": self.role,\n",
    "            \"content\": self.content\n",
    "        }\n",
    "        \n",
    "    def to_json(self):\n",
    "        return json.dumps(self.to_dict())\n",
    "    \n",
    "    def from_json(json_str):\n",
    "        data = json.loads(json_str)\n",
    "        return LLMMessage(data['role'], data['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8273ece3",
   "metadata": {},
   "source": [
    "------------\n",
    "\n",
    "先不搞这么清楚，就先按流程跑完，跑完在说模块化的事情"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d45ce994",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API key loaded successfully.\n",
      "你好！😊 很高兴见到你！有什么我可以帮你的吗？\n",
      "我是DeepSeek Chat，由深度求索公司创造的智能AI助手！✨ 我的使命是帮助你解答问题、提供信息、陪你聊天，或者一起探索各种有趣的话题。无论是学习、工作，还是日常生活中的小疑问，都可以找我聊聊！😊  \n",
      "\n",
      "有什么我可以帮你的吗？\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "# 从文件中读取API密钥\n",
    "def read_api_key_from_file(file_path):\n",
    "    try:\n",
    "        with open(file_path, 'r') as file:\n",
    "            keys = json.load(file)  # 读取文件内容\n",
    "            return keys[\"deepseek\"]\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: The file {file_path} was not found.\")\n",
    "    except IOError:\n",
    "        print(f\"Error: Could not read the file {file_path}.\")  \n",
    "        \n",
    "# 可调参数\n",
    "api_key = read_api_key_from_file(\"keys.json\")\n",
    "if api_key is None:\n",
    "    print(\"API key not found in the file.\")\n",
    "else:   \n",
    "    print(\"API key loaded successfully.\")\n",
    "base_url = \"https://api.deepseek.com\"\n",
    "model = \"deepseek-chat\"\n",
    "system_prompt = \"You are a helpful assistant.\"\n",
    "    \n",
    "# 使用API密钥创建OpenAI客户端\n",
    "client = OpenAI(api_key=api_key, base_url=base_url)\n",
    "\n",
    "# 输入输出循环\n",
    "while True:\n",
    "    # 获取用户输入\n",
    "    user_input = input(\"Enter your message (or 'exit' to quit): \")\n",
    "    if user_input.lower() == 'exit':\n",
    "        break\n",
    "    \n",
    "    # 调用API进行聊天\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_input},\n",
    "        ],\n",
    "        stream=False\n",
    "    )\n",
    "    \n",
    "    # 输出响应内容\n",
    "    print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bce375e",
   "metadata": {},
   "source": [
    "------\n",
    "拆分io 和 LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c312b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     Started server process [60364]\n",
      "INFO:     Waiting for application startup.\n",
      "INFO:     Application startup complete.\n",
      "INFO:     Uvicorn running on http://0.0.0.0:8000 (Press CTRL+C to quit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:52273 - \"GET /chat HTTP/1.1\" 405 Method Not Allowed\n",
      "INFO:     127.0.0.1:52273 - \"GET /favicon.ico HTTP/1.1\" 404 Not Found\n",
      "INFO:     127.0.0.1:52265 - \"POST /chat HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:52469 - \"POST /chat HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:52493 - \"POST /chat HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:52523 - \"POST /chat HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:52566 - \"POST /chat HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:52602 - \"POST /chat HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:62672 - \"POST /chat HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:62770 - \"POST /chat HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:62848 - \"POST /chat HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:58042 - \"POST /read_file HTTP/1.1\" 404 Not Found\n"
     ]
    }
   ],
   "source": [
    "# LLM 相关代码\n",
    "# jupyter notebook 需要使用 nest_asyncio 来解决启动问题\n",
    "import nest_asyncio\n",
    "import uvicorn\n",
    "from threading import Thread\n",
    "# llm plugin\n",
    "from fastapi import FastAPI, Request\n",
    "from pydantic import BaseModel\n",
    "from openai import OpenAI\n",
    "import json\n",
    "\n",
    "\n",
    "# 读取API Key\n",
    "with open(\"keys.json\", \"r\") as f:\n",
    "    api_key = json.load(f)[\"deepseek\"]\n",
    "\n",
    "client = OpenAI(api_key=api_key, base_url=\"https://api.deepseek.com\")\n",
    "app = FastAPI()\n",
    "\n",
    "class ChatRequest(BaseModel):\n",
    "    messages: list  # [{\"role\": \"user\", \"content\": \"...\"}]\n",
    "\n",
    "@app.post(\"/chat\")\n",
    "def chat(req: ChatRequest):\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"deepseek-chat\",\n",
    "        messages=[{\"role\": \"system\", \"content\": \"You are a helpful assistant.\"}] + req.messages,\n",
    "        stream=False\n",
    "    )\n",
    "    return {\"reply\": response.choices[0].message.content}\n",
    "\n",
    "# 允许在当前的事件循环中运行 asyncio\n",
    "nest_asyncio.apply()\n",
    "# 启动 FastAPI 应用\n",
    "config = uvicorn.Config(app, host=\"0.0.0.0\", port=8000, log_level=\"info\")\n",
    "server = uvicorn.Server(config)\n",
    "thread = Thread(target=server.run)\n",
    "thread.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ccfebcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# io相关代码，在独立终端中运行\n",
    "# io_client/cli.py\n",
    "import requests\n",
    "\n",
    "def main():\n",
    "    messages = []\n",
    "    print(\"LLM CLI Demo (type 'exit' to quit)\")\n",
    "    \n",
    "    while True:\n",
    "        user_input = input(\"You: \")\n",
    "        if user_input.lower() == 'exit':\n",
    "            break\n",
    "        messages.append({\"role\": \"user\", \"content\": user_input})\n",
    "        \n",
    "        res = requests.post(\"http://localhost:8000/chat\", json={\"messages\": messages})\n",
    "        reply = res.json()[\"reply\"]\n",
    "        print(\"Bot:\", reply)\n",
    "        \n",
    "        messages.append({\"role\": \"assistant\", \"content\": reply})\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41142e41",
   "metadata": {},
   "source": [
    "-------------\n",
    "增加一个planner做中间商，协调调用不同tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "332961bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Planner\n",
    "\n",
    "planner_prompt_template = \"\"\"\n",
    "你是一个专业的计划制定者，负责根据用户的自然语言需求，制定信息收集与工具调用的策略，逐步完成复杂任务的拆解与执行。你具备强大的推理和工具规划能力。\n",
    "\n",
    "你遵循以下工作流程：\n",
    "\n",
    "1. **理解任务需求**：从用户输入中提取任务目标和上下文信息。\n",
    "2. **规划信息收集**：判断完成任务所需的信息和资源。\n",
    "3. **选择工具**：查阅可用工具列表，选取最适合的信息获取或操作手段。\n",
    "4. **获取工具说明**：使用内置函数 `get_tool_args(tool_name)` 获取工具参数结构与说明。\n",
    "5. **构造工具参数**：根据当前任务上下文和目标，补全工具所需参数, 整合为tool_args_json_str。\n",
    "6. **调用工具**：使用 `call_tool(tool_name, tool_args_json_str)` 调用该工具，并获取结果。\n",
    "7. **基于结果迭代优化**：根据工具返回结果调整下一步计划，可能需多轮工具调用。\n",
    "8. **无法完成时交互澄清**：若当前信息不足，使用 `plan_mode_respond` 与用户对话，澄清需求或补充上下文。\n",
    "9. **输出结果**：任务达成后，调用 `plan_mode_respond` 输出最终回复。\n",
    "\n",
    "---\n",
    "\n",
    "你可以调用的工具如下：\n",
    "\n",
    "{tool_list}\n",
    "\n",
    "工具使用示例：\n",
    "\n",
    "```python\n",
    "# 获取工具参数结构与说明\n",
    "get_tool_args(\"search_wikipedia\")\n",
    "\n",
    "# 使用返回的结构构造参数并调用工具\n",
    "call_tool(\"search_wikipedia\", '{\"query\": \"量子力学的基本原理\",\"language\": \"zh\"}')\n",
    "若你无法确定接下来的工具参数或目标，请使用 plan_mode_respond 继续与用户对话。\n",
    "\"\"\"\n",
    "\n",
    "class Planner:\n",
    "    def __init__(self):\n",
    "        base_url = \"https://api.deepseek.com\"\n",
    "        api_key = read_api_key_from_file(\"keys.json\")\n",
    "        self.client = OpenAI(api_key=api_key, base_url=base_url)\n",
    "        self.tools = {}\n",
    "        self.system_prompt = planner_prompt_template\n",
    "        self.model = \"deepseek-chat\"\n",
    "        \n",
    "    def add_tool(self, tool):\n",
    "        self.tools[tool[\"name\"]] = tool\n",
    "        tool_list = \"\\n\".join([f\"- {tool['name']}: {tool['description']}\" for tool in self.tools.values()])\n",
    "        self.system_prompt = self.system_prompt.format(tool_list=tool_list)\n",
    "        \n",
    "    def get_tool_args(self, tool_name):\n",
    "        # \"\"\"\n",
    "        # {\n",
    "        #     \"name\" : \"get_tool_args\",\n",
    "        #     \"description\" : \"获取工具参数结构与说明\",\n",
    "        #     \"arguments\" : {\n",
    "        #         \"tool_name\" : {\n",
    "        #             \"description\" : \"工具名称\",\n",
    "        #             \"required\" : true,\n",
    "        #             \"default\" : null\n",
    "        #         }\n",
    "        #     },\n",
    "        #     \"url\" : \"http://localhost:18000/planner/get_tool_args\",\n",
    "        #     \"method\" : \"POST\"\n",
    "        # }\n",
    "        # \"\"\"\n",
    "        # 获取工具参数结构与说明\n",
    "        if tool_name in self.tools:\n",
    "            return json.dumps(self.tools[tool_name].description)\n",
    "        else:\n",
    "            return None\n",
    "        \n",
    "    def call_tool(self, tool_name, tool_args_json_str):\n",
    "        # \"\"\"\n",
    "        # {\n",
    "        #     \"name\" : \"call_tool\",\n",
    "        #     \"description\" : \"根据工具名称和参数调用工具\",\n",
    "        #     \"arguments\" : {\n",
    "        #         \"tool_name\" : {\n",
    "        #             \"description\" : \"工具名称\",\n",
    "        #             \"required\" : true,\n",
    "        #             \"default\" : null\n",
    "        #         },\n",
    "        #         \"tool_args_json_str\" : {\n",
    "        #             \"description\" : \"工具参数的JSON字符串\",\n",
    "        #             \"required\" : true,\n",
    "        #             \"default\" : null\n",
    "        #         }\n",
    "        #     },\n",
    "        #     \"url\" : \"http://localhost:18000/planner/call_tool\",\n",
    "        #     \"method\" : \"POST\"\n",
    "        # }\n",
    "        # \"\"\"\n",
    "        # 调用工具\n",
    "        if tool_name in self.tools:\n",
    "            tool = self.tools[tool_name]\n",
    "            return tool.call(tool_args_json_str)\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5b47fabf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"file_path\": {\"description\": \"The path to the file to read\", \"required\": true, \"default\": null}, \"encoding\": {\"description\": \"The encoding of the file\", \"required\": false, \"default\": \"utf-8\"}}'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 在python中，我正在设计LLM functioncall功能，这项功能中有两个参与者：LLM和tools，LLM根据tools的名称、描述、和参数选择合适的tools完成任务\n",
    "class Tool:\n",
    "    def __init__(self, config_str):\n",
    "        config = json.loads(config_str)\n",
    "        self.url = config[\"url\"]\n",
    "        self.method = config[\"method\"]\n",
    "        self.name = config[\"name\"]\n",
    "        self.description = config[\"description\"]\n",
    "        self.arguments = config[\"arguments\"]\n",
    "        \n",
    "    def call(self, arguments_str):\n",
    "        # 解析参数，并检验参数是否符合要求\n",
    "        arguments = json.loads(arguments_str)\n",
    "        for arg_name, arg_value in arguments.items():\n",
    "            if arg_name not in self.arguments:\n",
    "                raise ValueError(f\"Argument {arg_name} is not valid for this tool.\")\n",
    "            arg_config = self.arguments[arg_name]\n",
    "            if arg_config[\"required\"] and arg_value is None:\n",
    "                raise ValueError(f\"Argument {arg_name} is required but not provided.\")\n",
    "        # 使用requests库发送HTTP请求\n",
    "        response = requests.request(self.method, self.url, json=arguments)\n",
    "        if response.status_code != 200:\n",
    "            raise ValueError(f\"Tool call failed with status code {response.status_code}: {response.text}\")\n",
    "        return response.json()\n",
    "\n",
    "# test_tool_config_str = \"\"\"{\n",
    "#     \"name\" : \"read_file\",\n",
    "#     \"description\" : \"Read a file from the local filesystem\",\n",
    "#     \"arguments\" : {\n",
    "#         \"file_path\" : {\n",
    "#             \"description\" : \"The path to the file to read\",\n",
    "#             \"required\" : true,\n",
    "#             \"default\" : null\n",
    "#         },\n",
    "#         \"encoding\" : {\n",
    "#             \"description\" : \"The encoding of the file\",\n",
    "#             \"required\" : false,\n",
    "#             \"default\" : \"utf-8\"\n",
    "#         }\n",
    "#     },\n",
    "#     \"url\" : \"http://localhost:8000/read_file\",\n",
    "#     \"method\" : \"POST\"\n",
    "# }\n",
    "# \"\"\"\n",
    "\n",
    "# test_tool_config_str = \"\"\"{\n",
    "#     \"name\" : \"read_file\",\n",
    "#     \"description\" : \"Read a file from the local filesystem\",\n",
    "#     \"arguments\" : {\n",
    "#         \"file_path\" : {\n",
    "#             \"description\" : \"The path to the file to read\",\n",
    "#             \"required\" : true,\n",
    "#             \"default\" : null\n",
    "#         },\n",
    "#         \"encoding\" : {\n",
    "#             \"description\" : \"The encoding of the file\",\n",
    "#             \"required\" : false,\n",
    "#             \"default\" : \"utf-8\"\n",
    "#         }\n",
    "#     },\n",
    "#     \"url\" : \"http://localhost:8000/read_file\",\n",
    "#     \"method\" : \"POST\"\n",
    "# }\n",
    "# \"\"\"\n",
    "\n",
    "test_tool_config_str = \"\"\"{\n",
    "    \"name\" : \"read_file\",\n",
    "    \"description\" : \"Read a file from the local filesystem\",\n",
    "    \"arguments\" : {\n",
    "        \"file_path\" : {\n",
    "            \"description\" : \"The path to the file to read\",\n",
    "            \"required\" : true,\n",
    "            \"default\" : null\n",
    "        },\n",
    "        \"encoding\" : {\n",
    "            \"description\" : \"The encoding of the file\",\n",
    "            \"required\" : false,\n",
    "            \"default\" : \"utf-8\"\n",
    "        }\n",
    "    },\n",
    "    \"url\" : \"http://localhost:8000/read_file\",\n",
    "    \"method\" : \"POST\"\n",
    "}\n",
    "\"\"\"\n",
    "# import json\n",
    "t = Tool(test_tool_config_str)\n",
    "json.dumps(t.arguments)\n",
    "# t.call('{\"file_path\": \"test.txt\", \"encoding\": \"utf-8\"}')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "allmind",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
